# This file will run all the scripts needed to create a finalied .csv file containing %-ile rainfall data 
# Caleb Bitting (Colby Class of 2023)
# Written for research for Professor Daniel LaFave at Colby College
#

import os
import argparse
import itertools
import numpy as np
import pandas as pd
import csv_polishing
import rainfall_sums
import gamma_calculations

def commandLineParser():
    '''This function parses the command line arguments
    
    Returns:
        argparse.namespace: an argparse namespace representing the command line arguments
    '''
    parser = argparse.ArgumentParser()
    parser.add_argument('unit_code', type=int, help='the unit code that designates the area of interest. See ./resources/unit_name.txt for list of unit codes.')
    parser.add_argument('distance', type=float, help='the maximum distance (in km) allowed between a DHS center and a precip grid center.')
    parser.add_argument('len_years', type=int, help='the number of years to use to fit each gamma distribution.')
    parser.add_argument('--output_file', type=str, default='cleanGamma_data.csv', help='the name of the processed csv. Defaults to cleanGamma_data.csv')
    parser.add_argument('--windows', '-w', type=str, help='the file path for the list of the names of precip files.')
    parser.add_argument('--testing', action='store_true', help='enter testing mode. All functions will be passed testing=True where possible.')
    parser.add_argument('--pickle', action='store_true', help='read distance data from pickle generated by determine_distance.py')
    args = parser.parse_args()

    return args

def getNum(biggest, name):
    usr_inp = input(f'{name.capitalize()} number:  ')
    if int(usr_inp) > biggest:
        getNum(biggest)

    return int(usr_inp)

def printClearLine():
    _, columns = os.popen('stty size', 'r').read().split()
    fancy_sep = ['-' for _ in range(int(columns))]
    print(''.join(fancy_sep)) 

def getFile(extention, name):
    # find shapefiles recursively
    disp_name = []
    paths = []
    for root, dirs, files in os.walk('.'):
        for file in files:
            if file.endswith(extention):
                disp_name.append(file)                                 # name for display
                paths.append(os.path.join(root, file))                 # path for later use
    if len(disp_name) == 0:
        raise Exception(f'No {name}s were found.')
    else:
        printClearLine()
        print(f'Which {name} would you like to use?')
        for index, shapefile in enumerate(disp_name):
            print(f'[{index+1}]\t{shapefile}')

    usr_shp_file = getNum(len(disp_name), name)

    return paths[usr_shp_file - 1]

def main():
    # command-line arguments
    cmd_args = commandLineParser()
    cmd_args.determine_distance = False
    cmd_args.shapefile_path = getFile('.shp', 'shapefile')
    if cmd_args.pickle:
        cmd_args.pickle_path = getFile('.pickle', 'pickle')
    # get rainfall data
    gdf = rainfall_sums.body(cmd_args)
    gdf.to_csv('test.csv', index=False)
    # eye breathing room
    _, columns = os.popen('stty size', 'r').read().split()
    fancy_sep = ['-' for _ in range(int(columns))]
    print(''.join(fancy_sep)) 
    # get percentile data
    rainfall_list = gdf['Rainfall Totals'].tolist()
    percentiles = gamma_calculations.body(rainfall_list, cmd_args)
    # edit csv
    year = 1950 + cmd_args.len_years
    df = csv_polishing.body(rainfall_list, percentiles, year, cmd_args)
    # get DHSID
    DHSID_col = gdf['DHSID'].repeat(len(percentiles[0]))
    DHSID_col = DHSID_col.reset_index(drop=True)
    df.insert(0, 'DHSID', DHSID_col, allow_duplicates=True)
    df.drop('Location', axis=1, inplace=True)
    # output
    df.to_csv(cmd_args.output_file, index=False)

if __name__ == '__main__':
    main()